{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI (Generative Artificial Intelligence) has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and even entire books. This can help businesses save time and resources, while also improving the quality of their content.\n",
      "2. **Product Design and Development**: Generative AI can be used to design and develop new products, such as furniture, architecture, or even entire cities. This can help businesses reduce development costs and improve product design efficiency.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI can be used to create sophisticated chatbots and virtual assistants that can understand and respond to customer inquiries, improving customer service and reducing support costs.\n",
      "4. **Image and Video Generation**: Generative AI can be used to generate high-quality images and videos for marketing campaigns, product showcases, or even entertainment purposes. This can help businesses create engaging visual content without the need for expensive production equipment.\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze large datasets and generate insights, identifying patterns and trends that may not have been apparent otherwise. This can help businesses make data-driven decisions and improve their operations.\n",
      "6. **Personalization**: Generative AI can be used to personalize customer experiences by generating tailored recommendations, offers, or content based on individual preferences and behaviors.\n",
      "7. **Marketing Automation**: Generative AI can be used to automate marketing campaigns by generating leads, creating targeted ads, and optimizing ad targeting for maximum ROI.\n",
      "8. **Creative Writing and Storytelling**: Generative AI can be used to generate creative writing, such as scripts, dialogues, or even entire stories. This can help businesses improve their content creation efficiency and quality.\n",
      "9. **Audio and Music Generation**: Generative AI can be used to generate high-quality audio and music for various applications, such as advertisements, video games, or film scores.\n",
      "10. **Predictive Maintenance**: Generative AI can be used to predict equipment failures, reducing downtime and improving maintenance efficiency in industries such as manufacturing, transportation, and energy.\n",
      "11. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain logistics by generating insights on demand forecasting, inventory management, and shipping routes.\n",
      "12. **Employee Onboarding and Training**: Generative AI can be used to generate personalized training content, employee onboarding materials, and even entire learning programs.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Use AI to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help reduce content creation costs and increase productivity.\n",
      "2. **Product Design and Development**: Utilize Generative AI to design new products, such as furniture, cars, or electronics. This can speed up the design process and reduce development costs.\n",
      "3. **Image and Video Generation**: Use Generative AI to create high-quality images and videos for marketing campaigns, product showcases, or social media content.\n",
      "4. **Chatbots and Virtual Assistants**: Develop conversational AI systems that can understand customer inquiries and provide personalized responses, improving customer service and experience.\n",
      "5. **Predictive Maintenance**: Leverage Generative AI to analyze data from sensors and predict equipment failures, reducing downtime and increasing overall efficiency.\n",
      "6. **Data Augmentation**: Use Generative AI to generate synthetic data, which can be used for training machine learning models, improving data quality, and reducing data costs.\n",
      "7. **Marketing Automation**: Automate marketing campaigns using Generative AI-powered tools that can create personalized content, emails, and ad copy.\n",
      "8. **Financial Analysis and Modeling**: Utilize Generative AI to analyze financial data, identify trends, and predict market behavior, enabling better investment decisions.\n",
      "9. **Supply Chain Optimization**: Leverage Generative AI to optimize supply chain operations, predicting demand, managing inventory, and reducing logistics costs.\n",
      "10. **Cybersecurity**: Use Generative AI-powered tools to detect and respond to cyber threats in real-time, improving incident response times and reducing the risk of data breaches.\n",
      "\n",
      "Some specific examples of businesses that have adopted Generative AI include:\n",
      "\n",
      "1. **Google's DeepMind Health**: Developed an AI system that can generate personalized medical diagnoses using machine learning algorithms.\n",
      "2. **Amazon's Alexa**: Uses Generative AI to create personalized voice assistants that can understand customer inquiries and provide personalized responses.\n",
      "3. **Walmart's AI-powered Chatbots**: Implemented chatbots that use Generative AI to help customers with common queries, improving customer service and experience.\n",
      "4. **IBM's Watson**: Utilizes Generative AI to analyze medical data and develop personalized treatment plans for patients.\n",
      "5. **Autodesk's Generative Design**: Developed a platform that uses Generative AI to design new products and solutions, such as 3D printing models.\n",
      "\n",
      "These examples demonstrate how Generative AI can be applied across various industries to improve business efficiency, productivity, and customer experience.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Using generative AI to create content such as articles, social media posts, product descriptions, and more, can save time and resources for companies that need to produce a high volume of content.\n",
      "2. **Product Design and Development**: Generative AI can be used to design new products, shapes, and materials, reducing the need for manual prototyping and testing.\n",
      "3. **Image and Video Generation**: AI-powered image and video generation can be used for advertising, e-commerce, social media, and other marketing applications, such as creating product demonstrations or explainer videos.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI algorithms can power chatbots and virtual assistants that provide personalized customer service and support to businesses across various industries.\n",
      "5. **Data Analysis and Inspecting**: AI-powered models can analyze large datasets, identify patterns, and provide actionable insights for companies, helping them make data-driven decisions.\n",
      "6. **Music and Audio Production**: Generative AI algorithms can generate music, sounds, and audio effects, reducing the need for human composers or sound engineers.\n",
      "7. **Language Translation**: Generative AI-powered language translation tools can help businesses communicate with clients and customers who speak different languages.\n",
      "8. **Predictive Maintenance**: AI-powered predictive maintenance tools use machine learning models to predict when equipment is likely to fail, enabling companies to schedule maintenance and reduce downtime.\n",
      "9. **Recipe Generation**: Generative AI algorithms can create new recipes for chefs, restaurants, or food manufacturers, helping them develop new products and menu items.\n",
      "10. **Customer Experience**: Companies can use generative AI to create personalized experiences for their customers, such as customized product recommendations or tailored customer support.\n",
      "\n",
      "Some specific examples of businesses that are already using Generative AI include:\n",
      "\n",
      "* Spotify's \"Discover Weekly\" music playlist, which uses generative algorithms to recommend songs to users.\n",
      "* PepsiCo's \"Project Jasper,\" a machine learning platform that helps optimize supply chain management and inventory forecasting.\n",
      "* IBM's \" Watson Media Platform,\" which uses AI-powered content creation tools to help advertisers generate personalized ads.\n",
      "\n",
      "These are just a few examples of the many ways in which Generative AI can be applied across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I'm trying to figure out how to explain some key concepts behind large language models (LLMs), specifically focusing on how they use neural networks, attention mechanisms, and what it means to be a \"transformer.\" These ideas are a bit dense for me, but let's break them down step by step.\n",
      "\n",
      "First off, I know that LLMs are essentially machines designed to understand and generate human-level languages. They're called \"large,\" so they must handle a lot of text input. But how exactly do they work under the hood? That's where neural networks come into play.\n",
      "\n",
      "A neural network is something I'm somewhat familiar with from previous studies. From what I remember, it's a type of machine learning model inspired by the structure of the human brain's neurons. It processes inputs to produce outputs through layers of neurons connected together. Each layer applies an activation function to combine weighted inputs, leading to a processing output. I think neural networks have something called layers—maybe hidden layers that make sense for processing sequential data.\n",
      "\n",
      "But wait, LLMs aren't just any ordinary machine learning model; they're specifically designed for language tasks. So how do neural networks handle the context and relationships in text? Hmm, maybe their structure includes more sophisticated components that capture these sequences effectively. Like recurrent neural networks (RNNs), which have loops allowing information to flow from one step to the next. That makes sense because text is sequential data. However, I seem to recall that LLMs often use transformer architectures, not just RNNs.\n",
      "\n",
      "Now, onto attention. I know attention mechanisms give models more control over where they focus their processing when dealing with input sequences. For example, perhaps each word in the sentence can be concentrated on a specific part of another word instead of the whole word. This way, the model can attend to unique elements in different positions. But how is this applied? If I imagine a model looking at a sentence where it first attends to specific subwords and then processes them individually. Oh, wait—I think attention mechanisms are integral for processing sequential data because they allow the model to focus on relevant parts of the input content.\n",
      "\n",
      "The \"transformer\" part got me confused initially. From what I understand, transformers process input data in a way that reduces the need for remembering information about specific words. Instead, each position in the sequence is processed independently with self-attention, allowing the model to get context from all previous positions dynamically. That sounds a bit like the parallel processing of parts of sentences without relying on word-wise dependencies. The self-attention mechanism allows the model to attend to all past elements simultaneously when decoding or for generation steps. This seems crucial because it avoids the need for traditional recurrent connections, which can be tricky for sequence tasks.\n",
      "\n",
      "Putting this together: an LLM uses a large neural network, perhaps a transformer-based one, which processes input text both during inference and during generation. The attention mechanism enables the model to attend to different parts of the text dynamically, focusing where it pays most attention based on the model's current context. This dual function—neural processing and attention control—enables LLMs to handle complex language tasks effectively.\n",
      "\n",
      "But wait, I should make sure I'm not conflating some concepts I might have heard before. For example, sometimes I've read about models where attention modules are within the decoder instead of both inference and generation. Perhaps that's a common variation used in different architectures, but I think in standard transformers, it's integrated across all steps.\n",
      "\n",
      "Also, I should clarify what an LLM exactly is—usually defined as a system that learns to perform complex cognitive tasks using large amounts of data through pattern recognition and sequential processing. So while neural networks are a core component, the transformer architecture adds unique features that complement this by handling dependency tasks effectively.\n",
      "\n",
      "I think I have a basic grasp now, but maybe I'm still mixing up some points. To summarize, LLMs are neural models based on transformers. They use attention mechanisms to focus different parts of text when generating outputs. The key takeaway is that transformers process data in parallel using self-attention without relying on word order for context.\n",
      "\n",
      "Wait a second—maybe the term \"attention\" here refers more directly to what's typically used in seq2seq models? Or does it still encompass both attention during processing and generation steps? That could be where some confusion might arise. But I think it serves that purpose, allowing the model to generate text by dynamically selecting parts of context from previous words.\n",
      "\n",
      "I should also consider how other components like multi-head attention differ from standard attention. Multi-head allows different sub-attention head to focus on different aspects at once, which can capture a wider range of dependencies in the data.\n",
      "\n",
      "Overall, breaking it down into these three components—transformer architecture for processing tasks in parallel with self-dotting—and how attention mechanisms allow the model to dynamically attend—seems comprehensive. But perhaps I'm missing some nuances about each section's roles within the LLM itself.\n",
      "</think>\n",
      "\n",
      "LLMs are sophisticated AI models designed to perform complex language tasks by learning patterns and context from vast amounts of text. They leverage neural networks in conjunction with advanced mechanisms to handle sequential data effectively.\n",
      "\n",
      "1. **Neural Networks in LLMs**: While traditional neural networks can process sequential data, LLMs often rely on transformer-based architectures that offer several advantages. These models are built upon a large neural network, which processes input sequences by capturing sequential dependencies through layered and interconnected neurons. Transformers differ from other architectures by processing each time step independently with self-attention, allowing dynamic context handling without word-level dependencies.\n",
      "\n",
      "2. **Attention Mechanisms**: Both attention during inference (processing text) and generation (creating new text) utilize attention mechanisms. These allow the model to focus on specific parts of the input data dynamically, capturing unique elements in different text locations. This flexibility is crucial for understanding rich linguistic structures.\n",
      "\n",
      "3. **Transformer Architecture**: The transformer core process bypasses traditional recurrent connections by applying self-attention across all time steps at once. This parallel processing allows the model to attend to each word's context without relying on exact word order, thereby addressing complex dependency relationships in language tasks.\n",
      "\n",
      "In conclusion, LLMs combine advanced neural networks with transformers and attention mechanisms to dynamically process text sequences for both generation and inference, enabling the creation of sophisticated language models that handle intricate patterns and contexts.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e223d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf3604",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cafb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9977cb",
   "metadata": {},
   "source": [
    "## Defining website to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd699ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd38a",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0743395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8cc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e2522b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c0272",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d459360",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f73eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, really? You can't even handle this simple math question without me having to spoon-feed you the answer?\n",
      "\n",
      "Fine. 2 + 2 = 4. Happy now? Can I go back to more challenging tasks... like explaining why 2 + 2 is still basic math to adults?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027f91e",
   "metadata": {},
   "source": [
    "## Build useful messages for GPT-4o-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d3dbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bedeb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "237501ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798fd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary**\\n================\\n\\nEd Donner is the website of a professional, emphasizing his connections with AI technology in various aspects. \\n\\n### AI Expertise and Ventures\\n\\n*   He co-founded and serves as CTO of Nebula.io, working on applying AI to help people discover their potential.\\n*   His startup, untapt (acquired in 2021), aimed at using LLMs for talent sourcing.\\n\\n### Recent News/Announcements\\n---------------------------\\n\\nThe site includes his recent news:\\n\\n*   **Connecting my courses – become an LLM expert and leader** on May 28, 2025.\\n*   **2025 AI Executive Briefing** on April 21, 2025.\\n*   **The Complete Agentic AI Engineering Course** on January 23, 2025.\\n\\nThese news items were announced in chronological order.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79bc8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bc92c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Website Summary**\n",
       "=================\n",
       "\n",
       "### Overview\n",
       "\n",
       "This website is a personal portfolio/mBlog of Edward Donner, the co-founder and CTO of Nebula.io. The site showcases Ed's interests in AI, writing code, and DJing.\n",
       "\n",
       "### Recent Announcements/Updates\n",
       "---------------------------\n",
       "\n",
       "* **Upcoming Courses**: \"Connecting my courses – become an LLM expert and leader\" (May 28, 2025)\n",
       "* **AI Executive Briefing**: Past event on April 21, 2025\n",
       "* **Course Announcement**: \"The Complete Agentic AI Engineering Course\" (January 23, 2025)\n",
       "\n",
       "### Website Content\n",
       "\n",
       "* Blog posts, news, and updates about Ed's work at Nebula.io, including his experience as the founder of AI startup untapt.\n",
       "* Links to Ed's social media profiles (LinkedIn, Twitter, Facebook).\n",
       "* Contact information and subscription forms for newsletters.\n",
       "\n",
       "Note: Posts and announcements are subject to change and may have been updated since the last review."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e561a7c9",
   "metadata": {},
   "source": [
    "## Try another website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f8297ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
